<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>B-LoRA</title>
      <link href="/2024/10/26/b-lora/"/>
      <url>/2024/10/26/b-lora/</url>
      
        <content type="html"><![CDATA[<h1 id="B-lora"><a href="#B-lora" class="headerlink" title="B-lora"></a>B-lora</h1><p>Title: Implicit Style-Content Separation using B-LoRA</p><p>概括: 观察attntion模块，本质上是发现了attention模块具有独立性</p><p>github: <a href="https://github.com/yardenfren1996/B-LoRA">https://github.com/yardenfren1996/B-LoRA</a></p><p>paper: <a href="https://arxiv.org/pdf/2403.14572">https://arxiv.org/pdf/2403.14572</a></p><p>network: <img src="/figures/00_01.png" alt="network.png"></p><h2 id="method"><a href="#method" class="headerlink" title="method"></a>method</h2><ol><li><p>如下图，SD模型中prompt embedding的描述，文中将不同的prompt分别注入到不同的attention层中，观察某一个层中prompt改变对整体生成图像的影响，再通过CLIP将图像映射到潜空间，计算替换一个prompt出图和prompt本身的余弦相似度→发现第二个和第四个bdflock对应内容的生成，第五个block对应颜色的生成</p><p> <img src="/figures/00_00.png" alt="baseline.png"></p></li><li><p>lora-based separation with B_lora</p><ol><li>通过实验发现更改 $∆ W^{4}, ∆W^{5}$的效果最好，其中$∆ W^{4}$ $∆ W^{4}, ∆W^{5}$分别代表内容信息和风格信息</li><li>将这种只需要训练两个模块的叫做B-lora—减少训练参数量</li></ol></li><li><p>B-lora for image stylization</p><ol><li><p>通过输入text-prompt 训练两个矩阵，实现了对style和content的解耦，并且实现了仅加入对应权重实现风格融合</p><p> <img src="figures/00_01.png" alt="network.png"></p></li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
